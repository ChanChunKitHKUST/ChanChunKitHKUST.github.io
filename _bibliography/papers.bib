---
---
@article{chan2024negotiationtom,
  abbr={EMNLP 2024},
  bibtex_show={true},
  selected={true},
  title={NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding},
  author={Chan, Chunkit and Jiayang, Cheng and Yim, Yauwai and Deng, Zheye and Fan, Wei and Li, Haoran and Liu, Xin and Zhang, Hongming and Wang, Weiqi and Song, Yangqiu},
  journal={arXiv preprint arXiv:2404.13627},
  year={2024}
}

@article{DBLP:journals/corr/abs-2408-02559,
  abbr={Arxiv},
  bibtex_show={true},
  selected={true},
  author       = {Yauwai Yim and
                  Chunkit Chan and
                  Tianyu Shi and
                  Zheye Deng and
                  Wei Fan and
                  Tianshi Zheng and
                  Yangqiu Song},
  title        = {Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan:
                  {A} Multi-Player Cooperative Game under Imperfect Information},
  journal      = {CoRR},
  volume       = {abs/2408.02559},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2408.02559},
  doi          = {10.48550/ARXIV.2408.02559},
  eprinttype    = {arXiv},
  eprint       = {2408.02559},
  timestamp    = {Thu, 12 Sep 2024 21:06:48 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2408-02559.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2304-14827,
  abbr={EACL 2024},
  bibtex_show={true},
  selected={true},
  author       = {Chunkit Chan and
                  Jiayang Cheng and
                  Weiqi Wang and
                  Yuxin Jiang and
                  Tianqing Fang and
                  Xin Liu and
                  Yangqiu Song},
  title        = {ChatGPT Evaluation on Sentence Level Relations: {A} Focus on Temporal,
                  Causal, and Discourse Relations},
  journal      = {Findings-EACL2024},
  volume       = {abs/2304.14827},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2304.14827},
  doi          = {10.48550/arXiv.2304.14827},
  eprinttype    = {arXiv},
  eprint       = {2304.14827},
  timestamp    = {Thu, 04 May 2023 15:47:42 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2304-14827.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/acl/ChanLCLSWS23,
  abbr={ACL 2023},
  bibtex_show={true},
  selected={true},
  author       = {Chunkit Chan and
                  Xin Liu and
                  Jiayang Cheng and
                  Zihan Li and
                  Yangqiu Song and
                  Ginny Y. Wong and
                  Simon See},
  editor       = {Anna Rogers and
                  Jordan L. Boyd{-}Graber and
                  Naoaki Okazaki},
  title        = {DiscoPrompt: Path Prediction Prompt Tuning for Implicit Discourse
                  Relation Recognition},
  booktitle    = {Findings of the Association for Computational Linguistics: {ACL} 2023,
                  Toronto, Canada, July 9-14, 2023},
  pages        = {35--57},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://doi.org/10.18653/v1/2023.findings-acl.4},
  doi          = {10.18653/v1/2023.findings-acl.4},
  timestamp    = {Thu, 10 Aug 2023 12:35:51 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/ChanLCLSWS23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{chan-etal-2023-self,
    abbr={AACL 2023},
    selected={true},
    bibtex_show={true},
    title = "Self-Consistent Narrative Prompts on Abductive Natural Language Inference",
    author = "Chan, Chunkit  and
      Liu, Xin  and
      Chan, Tsz Ho  and
      Cheng, Jiayang  and
      Song, Yangqiu  and
      Wong, Ginny  and
      See, Simon",
    editor = "Park, Jong C.  and
      Arase, Yuki  and
      Hu, Baotian  and
      Lu, Wei  and
      Wijaya, Derry  and
      Purwarianti, Ayu  and
      Krisnadhi, Adila Alfa",
    booktitle = "Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = nov,
    year = "2023",
    address = "Nusa Dua, Bali",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.ijcnlp-main.67",
    pages = "1040--1057",
}

@inproceedings{jiang-etal-2023-lion,
    abbr={EMNLP 2023},
    bibtex_show={true},
    selected={true},
    title = "Lion: Adversarial Distillation of Proprietary Large Language Models",
    author = "Jiang, Yuxin  and
      Chan, Chunkit  and
      Chen, Mingyang  and
      Wang, Wei",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.189",
    doi = "10.18653/v1/2023.emnlp-main.189",
    pages = "3134--3154",
    abstract = "The practice of transferring knowledge from a sophisticated, proprietary large language model (LLM) to a compact, open-source LLM has garnered considerable attention. Previous works have focused on a unidirectional knowledge distillation way by aligning the responses of the student model with those of the teacher model to a set of instructions. Nevertheless, they overlooked the possibility of incorporating any {``}feedback{''}{--}identifying challenging instructions where the student model{'}s performance falls short{--}to boost the student model{'}s proficiency iteratively. To this end, we propose a novel adversarial distillation framework for a more efficient knowledge transfer. Leveraging the versatile role adaptability of LLMs, we prompt the teacher model to identify {``}hard{''} instructions and generate new {``}hard{''} instructions for the student model, creating a three-stage adversarial loop of imitation, discrimination, and generation. By applying this adversarial framework, we successfully transfer knowledge from ChatGPT to a student model (named Lion), using a mere 70k training data. Our results show that Lion-13B not only achieves comparable open-ended generation capabilities to ChatGPT but surpasses conventional state-of-the-art (SOTA) instruction-tuned models like Vicuna-13B by 55.4{\%} in challenging zero-shot reasoning benchmarks such as BIG-Bench Hard (BBH) and 16.7{\%} on AGIEval.",
}

@article{deng2024text,
  abbr={EMNLP 2024},
  bibtex_show={true},
  selected={true},
  title={Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction},
  author={Deng, Zheye and Chan, Chunkit and Wang, Weiqi and Sun, Yuxi and Fan, Wei and Zheng, Tianshi and Yim, Yauwai and Song, Yangqiu},
  journal={arXiv preprint arXiv:2404.14215},
  year={2024}
}

@inproceedings{jiayang-etal-2023-storyanalogy,
      abbr={EMNLP 2023},
      bibtex_show={true},
    title = "{S}tory{A}nalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding",
    author = "Jiayang, Cheng  and
      Qiu, Lin  and
      Chan, Tsz  and
      Fang, Tianqing  and
      Wang, Weiqi  and
      Chan, Chunkit  and
      Ru, Dongyu  and
      Guo, Qipeng  and
      Zhang, Hongming  and
      Song, Yangqiu  and
      Zhang, Yue  and
      Zhang, Zheng",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.706",
    doi = "10.18653/v1/2023.emnlp-main.706",
    pages = "11518--11537",
    abstract = "Analogy-making between narratives is crucial for human reasoning. In this paper, we evaluate the ability to identify and generate analogies by constructing a first-of-its-kind large-scale story-level analogy corpus, StoryAnalogy, which contains 24K story pairs from diverse domains with human annotations on two similarities from the extended Structure-Mapping Theory. We design a set of tests on StoryAnalogy, presenting the first evaluation of story-level analogy identification and generation. Interestingly, we find that the analogy identification tasks are incredibly difficult not only for sentence embedding models but also for the recent large language models (LLMs) such as ChatGPT and LLaMa. ChatGPT, for example, only achieved around 30{\%} accuracy in multiple-choice questions (compared to over 85{\%} accuracy for humans). Furthermore, we observe that the data in StoryAnalogy can improve the quality of analogy generation in LLMs, where a fine-tuned FlanT5-xxl model achieves comparable performance to zero-shot ChatGPT.",
}


@misc{wang2024candle,
      abbr={ACL 2024},
      bibtex_show={true},
      title={CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning}, 
      author={Weiqi Wang and Tianqing Fang and Chunyang Li and Haochen Shi and Wenxuan Ding and Baixuan Xu and Zhaowei Wang and Jiaxin Bai and Xin Liu and Jiayang Cheng and Chunkit Chan and Yangqiu Song},
      year={2024},
      eprint={2401.07286},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@inproceedings{DBLP:conf/coling/JiayangQC0SZ24,
  abbr={COLING 2024},
  bibtex_show={true},
  selected={true},
  author       = {Cheng Jiayang and
                  Lin Qiu and
                  Chunkit Chan and
                  Xin Liu and
                  Yangqiu Song and
                  Zheng Zhang},
  editor       = {Nicoletta Calzolari and
                  Min{-}Yen Kan and
                  V{\'{e}}ronique Hoste and
                  Alessandro Lenci and
                  Sakriani Sakti and
                  Nianwen Xue},
  title        = {EventGround: Narrative Reasoning by Grounding to Eventuality-centric
                  Knowledge Graphs},
  booktitle    = {Proceedings of the 2024 Joint International Conference on Computational
                  Linguistics, Language Resources and Evaluation, {LREC/COLING} 2024,
                  20-25 May, 2024, Torino, Italy},
  pages        = {6622--6642},
  publisher    = {{ELRA} and {ICCL}},
  year         = {2024},
  url          = {https://aclanthology.org/2024.lrec-main.587},
  timestamp    = {Thu, 23 May 2024 16:47:05 +0200},
  biburl       = {https://dblp.org/rec/conf/coling/JiayangQC0SZ24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
